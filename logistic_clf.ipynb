{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code assumes you have equal number of instances of each class to make the implementation simpler\n",
    "num_i = 130 #number of instances per class\n",
    "num_c = 4 #number of classes\n",
    "beach = []\n",
    "city = []\n",
    "forest = []\n",
    "mountains = []\n",
    "\n",
    "for i in range(num_i):\n",
    "    beach.append(mpimg.imread('Dataset/Beach/image'+str(i)+'.jpg'))\n",
    "    city.append(mpimg.imread('Dataset/City/image'+str(i)+'.jpg'))\n",
    "    forest.append(mpimg.imread('Dataset/Forest/image'+str(i)+'.jpg'))\n",
    "    mountains.append(mpimg.imread('Dataset/Mountains/image'+str(i)+'.jpg'))\n",
    "    \n",
    "beach = np.array(beach)\n",
    "city = np.array(city)\n",
    "forest = np.array(forest)\n",
    "mountains = np.array(mountains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 299, 299, 3) ----> number of instaces, height, width, number of channels\n"
     ]
    }
   ],
   "source": [
    "#we have just imported .jpg images as numpy arrays\n",
    "print(city.shape, '---->', 'number of instaces, height, width, number of channels')\n",
    "num_i, height, width, channels = city.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.vstack((beach,city,forest,mountains)).reshape(num_i*num_c,-1) #unrolling each image into a long vector\n",
    "dataset = dataset/255 #normalizing\n",
    "labels = np.zeros(num_c*num_i)\n",
    "\n",
    "for i in range(num_c):\n",
    "    labels[i*num_i:(i+1)*num_i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 268203)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.astype(int)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.1, shuffle=True, stratify=labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.11, shuffle=True, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (416, 268203) ----> 90% of data\n",
      "X_val: (52, 268203) ----> 10% of data\n",
      "X_test: (52, 268203) ----> 10% of data\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape, '----> 90% of data')\n",
    "print('X_val:', X_val.shape, '----> 10% of data')\n",
    "print('X_test:', X_test.shape, '----> 10% of data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([104, 104, 104, 104], dtype=int64))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True) #checking if the split is stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "reg_constant = 0.08\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing logistic regression using TF\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=(None, height*width*channels), name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')\n",
    "\n",
    "with tf.name_scope('multiplication'):\n",
    "    logits = fully_connected(X, num_c, activation_fn=None, scope=\"outputs\")\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    tr_var = tf.trainable_variables()\n",
    "    reg_loss = tf.reduce_sum([tf.nn.l2_loss(v) for v in tr_var if 'bias' not in v.name]) * reg_constant\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)) + reg_loss\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('predict'):\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    predictions = tf.argmax(softmax, axis=1)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    good_pred = tf.cast(tf.equal(predictions, y), tf.float64)\n",
    "    accuracy = tf.reduce_mean(good_pred)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 152.222625951\n",
      "Training accuracy: 0.25\n",
      "Validation accuracy: 0.25\n",
      "Loss: 31.3866564797\n",
      "Training accuracy: 0.487980769231\n",
      "Validation accuracy: 0.519230769231\n",
      "Loss: 22.367673214\n",
      "Training accuracy: 0.526442307692\n",
      "Validation accuracy: 0.5\n",
      "Loss: 19.2944122588\n",
      "Training accuracy: 0.641826923077\n",
      "Validation accuracy: 0.673076923077\n",
      "Loss: 10.4670918894\n",
      "Training accuracy: 0.711538461538\n",
      "Validation accuracy: 0.615384615385\n",
      "Loss: 7.58961251442\n",
      "Training accuracy: 0.75\n",
      "Validation accuracy: 0.711538461538\n",
      "Loss: 3.79243498405\n",
      "Training accuracy: 0.817307692308\n",
      "Validation accuracy: 0.653846153846\n",
      "Loss: 1.99876342252\n",
      "Training accuracy: 0.855769230769\n",
      "Validation accuracy: 0.692307692308\n",
      "Loss: 1.11034908214\n",
      "Training accuracy: 0.894230769231\n",
      "Validation accuracy: 0.692307692308\n",
      "Loss: 0.779934392771\n",
      "Training accuracy: 0.949519230769\n",
      "Validation accuracy: 0.730769230769\n",
      "-----------------------\n",
      "Test accuracy: 0.788461538462\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        if epoch % 10 == 0:\n",
    "            tr_loss = loss.eval(feed_dict={X: X_train, y: y_train})\n",
    "            training_accuracy = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "            validation_accuracy = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "            print('Loss:', tr_loss)\n",
    "            print('Training accuracy:', training_accuracy)\n",
    "            print('Validation accuracy:', validation_accuracy)\n",
    "    \n",
    "    print('-----------------------')\n",
    "    test_accuracy = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
